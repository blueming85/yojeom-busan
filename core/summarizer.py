"""
ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œ ìš”ì•½ê¸° - BusanNewsSummarizer
===============================================
PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ GPTë¡œ ìš”ì•½ â†’ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±

ì£¼ìš” ê¸°ëŠ¥:
- PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF ì‚¬ìš©)
- OpenAI GPTë¥¼ ì´ìš©í•œ ì§€ëŠ¥í˜• ìš”ì•½
- íƒœê·¸ ìë™ ë¶„ë¥˜ ë° ê²€ì¦
- ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± ë° ì €ì¥
- ê°œë³„ URL í¬í•¨ ì§€ì›
- ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
"""

import os
import logging
import time
import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import openai
import fitz  # PyMuPDF
from datetime import datetime

from config import (
    OPENAI_API_KEY, OPENAI_MODEL, MAX_TOKENS, TEMPERATURE,
    AVAILABLE_TAGS, MD_DIR, PDF_DIR, ROOT_DIR
)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class BusanNewsSummarizer:
    """ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œ ìš”ì•½ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        if not OPENAI_API_KEY:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        self.client = openai.OpenAI(api_key=OPENAI_API_KEY)
        self.output_dir = MD_DIR
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
        logger.info("âœ… BusanNewsSummarizer ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•ˆì „ì„± ê°œì„ )"""
        doc = None
        try:
            logger.info(f"ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘: {Path(pdf_path).name}")
            
            # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
            if not os.path.exists(pdf_path):
                logger.error(f"âŒ PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {pdf_path}")
                return ""
            
            file_size = os.path.getsize(pdf_path)
            if file_size < 100:  # 100ë°”ì´íŠ¸ ë¯¸ë§Œ
                logger.error(f"âŒ PDF íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ: {file_size}ë°”ì´íŠ¸")
                return ""
            
            logger.info(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:,}ë°”ì´íŠ¸")
            
            # PDF ì—´ê¸°
            doc = fitz.open(pdf_path)
            
            if doc.page_count == 0:
                logger.error("âŒ PDFì— í˜ì´ì§€ê°€ ì—†ìŒ")
                return ""
            
            logger.info(f"ğŸ“‘ ì´ í˜ì´ì§€ ìˆ˜: {doc.page_count}")
            
            text_parts = []
            
            for page_num in range(doc.page_count):
                try:
                    page = doc[page_num]
                    page_text = page.get_text()
                    
                    if page_text.strip():
                        text_parts.append(page_text)
                        logger.debug(f"   í˜ì´ì§€ {page_num + 1}: {len(page_text)}ì ì¶”ì¶œ")
                    else:
                        logger.warning(f"   í˜ì´ì§€ {page_num + 1}: í…ìŠ¤íŠ¸ ì—†ìŒ")
                        
                except Exception as page_error:
                    logger.warning(f"   í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {page_error}")
                    continue
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
            full_text = "\n".join(text_parts)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            if full_text:
                # 1. ê³¼ë„í•œ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬
                full_text = re.sub(r'\n\s*\n', '\n\n', full_text)  # ì—°ì†ëœ ë¹ˆ ì¤„ì„ 2ê°œë¡œ ì œí•œ
                full_text = re.sub(r'[ \t]+', ' ', full_text)  # ì—°ì†ëœ ê³µë°±ì„ 1ê°œë¡œ
                full_text = re.sub(r'\n[ \t]+', '\n', full_text)  # ì¤„ ì‹œì‘ì˜ ê³µë°± ì œê±°
                
                # 2. ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                full_text = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,()[\]{}!?%-]', '', full_text)
                
                # 3. ìµœì¢… ì •ë¦¬
                full_text = full_text.strip()
            
            if len(full_text) < 50:
                logger.warning(f"âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ: {len(full_text)}ì")
                return ""
            
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(full_text)}ì ({doc.page_count}í˜ì´ì§€)")
            return full_text
            
        except Exception as e:
            logger.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
        
        finally:
            # ğŸ”§ ì•ˆì „í•œ document ë‹«ê¸°
            if doc is not None:
                try:
                    doc.close()
                    logger.debug("ğŸ“‹ PDF document ë‹«ê¸° ì™„ë£Œ")
                except Exception as close_error:
                    logger.warning(f"âš ï¸ PDF document ë‹«ê¸° ì‹¤íŒ¨: {close_error}")

    
    def generate_summary_with_gpt(self, content: str, source_url: str = "") -> Optional[Dict]:
        """GPTë¥¼ ì´ìš©í•œ ìš”ì•½ ìƒì„±"""
        try:
            # 1. ë‚´ìš© ê¸¸ì´ í™•ì¸ ë° ì œí•œ
            original_length = len(content)
            if original_length > 3000:
                content = content[:3000]
                logger.warning(f"ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ 3000ìë¡œ ìë¦„ (ì›ë³¸: {original_length}ì)")
            
            # 2. source_url ê¸°ë³¸ê°’ ì„¤ì •
            if not source_url:
                source_url = "https://www.busan.go.kr/nbtnewsBU"
                logger.info("source_urlì´ ì—†ì–´ì„œ ê¸°ë³¸ URL ì‚¬ìš©")
            
            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_summary_prompt(content, source_url)
            
            logger.info("ğŸ¤– GPT ìš”ì•½ ìƒì„± ìš”ì²­ ì¤‘...")
            
            # 4. GPT API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œë¥¼ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹œë¯¼ë“¤ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìì„¸í•˜ê³  ì¹œê·¼í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ frontmatter í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            summary_text = response.choices[0].message.content.strip()
            
            # 5. ì‘ë‹µ ê²€ì¦ ë° íŒŒì‹±
            if not summary_text:
                logger.error("âŒ GPT ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
                return None
            
            # 6. Frontmatter íŒŒì‹±
            metadata = self._parse_frontmatter(summary_text)
            if not metadata:
                logger.error("âŒ frontmatter íŒŒì‹± ì‹¤íŒ¨")
                return None
            
            # 7. source_url ì¬í™•ì¸ ë° ìˆ˜ì •
            if not metadata.get('source_url') or metadata.get('source_url') == "ì›ë¬¸_URL_ì—¬ê¸°_ì…ë ¥":
                metadata['source_url'] = source_url
                # summary_textì—ì„œë„ êµì²´
                summary_text = summary_text.replace("ì›ë¬¸_URL_ì—¬ê¸°_ì…ë ¥", source_url)
            
            logger.info("âœ… GPT ìš”ì•½ ìƒì„± ì™„ë£Œ")
            return {
                'metadata': metadata,
                'content': summary_text
            }
                
        except Exception as e:
            logger.error(f"âŒ GPT ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_summary_prompt(self, content: str, source_url: str) -> str:
        """ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
ë‹¤ìŒ ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„¸íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.

ë³´ë„ìë£Œ ë‚´ìš©:
{content}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

---
title: "ë³´ë„ìë£Œ ì œëª©"
date: "YYYY-MM-DD"
tags: ["íƒœê·¸1"]
thumbnail_summary: "80ì ì´ë‚´ í•œì¤„ìš”ì•½"
source_url: "{source_url}"
---

# ìƒì„¸ ìš”ì•½

## ğŸ“‹ ì£¼ìš” ë‚´ìš©
ì´ë²ˆ ë³´ë„ìë£Œì˜ ëª¨ë“  ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì‹œë¯¼ë“¤ì´ ì•Œì•„ì•¼ í•  ì¼ì •, ì¥ì†Œ, ì°¸ì—¬ë°©ë²•, í˜œíƒ, ì‹ ì²­ë°©ë²•, ì—°ë½ì²˜, ë°°ê²½, ê¸°ëŒ€íš¨ê³¼, ì˜ë¯¸ ë“± ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•´ì„œ ì™„ì „íˆ ëê¹Œì§€ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸
- ì£¼ìš” ëŒ€ìƒ: ëˆ„êµ¬ë¥¼ ìœ„í•œ ì •ì±…/í–‰ì‚¬ì¸ì§€
- ì¼ì • ë° ì¥ì†Œ: ì–¸ì œ, ì–´ë””ì„œ ì§„í–‰ë˜ëŠ”ì§€
- ì°¸ì—¬ ë°©ë²•: ì–´ë–»ê²Œ ì°¸ì—¬í•˜ê±°ë‚˜ ì‹ ì²­í•  ìˆ˜ ìˆëŠ”ì§€
- í˜œíƒ ë° ì§€ì›: ì–´ë–¤ í˜œíƒì´ë‚˜ ì§€ì›ì„ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€
- ë¬¸ì˜ì²˜: ìì„¸í•œ ì •ë³´ë‚˜ ë¬¸ì˜ë¥¼ ìœ„í•œ ì—°ë½ì²˜

## ğŸ“ ë¬¸ì˜ ë° ì‹ ì²­
ê´€ë ¨ ë¶€ì„œë‚˜ ê¸°ê´€ì˜ ì—°ë½ì²˜, ì›¹ì‚¬ì´íŠ¸, ì‹ ì²­ ë°©ë²• ë“±ì„ í¬í•¨í•´ì£¼ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸: {', '.join(AVAILABLE_TAGS)}
íƒœê·¸ëŠ” ë‚´ìš©ì— ê°€ì¥ ì í•©í•œ **1ê°œë§Œ** ì„ íƒí•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ---ë¡œ ê°ì‹¸ì§„ frontmatter í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”.
"""
    
    def _parse_frontmatter(self, content: str) -> Optional[Dict]:
        """Frontmatter íŒŒì‹±"""
        try:
            # frontmatter êµ¬ë¶„ì í™•ì¸
            if not content.startswith('---'):
                logger.error("frontmatter ì‹œì‘ êµ¬ë¶„ì(---) ì—†ìŒ")
                return None
            
            # ì¢…ë£Œ êµ¬ë¶„ì ì°¾ê¸°
            end_idx = content.find('---', 3)
            if end_idx == -1:
                logger.error("frontmatter ì¢…ë£Œ êµ¬ë¶„ì(---) ì—†ìŒ")
                return None
            
            # frontmatter ì¶”ì¶œ
            frontmatter_text = content[3:end_idx].strip()
            
            # YAML ìŠ¤íƒ€ì¼ íŒŒì‹±
            metadata = {}
            for line in frontmatter_text.split('\n'):
                line = line.strip()
                if not line or ':' not in line:
                    continue
                
                try:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()
                    
                    # ë”°ì˜´í‘œ ì œê±°
                    if value.startswith('"') and value.endswith('"'):
                        value = value[1:-1]
                    elif value.startswith("'") and value.endswith("'"):
                        value = value[1:-1]
                    
                    # tags í•„ë“œ íŠ¹ë³„ ì²˜ë¦¬
                    if key == 'tags':
                        if value.startswith('[') and value.endswith(']'):
                            # ["íƒœê·¸1", "íƒœê·¸2"] í˜•ì‹ íŒŒì‹±
                            tag_content = value[1:-1].strip()
                            if tag_content:
                                # ê°œë³„ íƒœê·¸ ì¶”ì¶œ
                                tags = []
                                for tag_item in tag_content.split(','):
                                    tag_item = tag_item.strip().strip('"\'')
                                    if tag_item:
                                        tags.append(tag_item)
                                metadata[key] = tags if tags else ["ì „ì²´"]
                            else:
                                metadata[key] = ["ì „ì²´"]
                        else:
                            metadata[key] = [value] if value else ["ì „ì²´"]
                    else:
                        metadata[key] = value
                        
                except ValueError:
                    logger.warning(f"frontmatter ë¼ì¸ íŒŒì‹± ì‹¤íŒ¨: {line}")
                    continue
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['title', 'date', 'tags', 'thumbnail_summary']
            for field in required_fields:
                if field not in metadata:
                    logger.warning(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                    # ê¸°ë³¸ê°’ ì„¤ì •
                    if field == 'title':
                        metadata[field] = "ë¶€ì‚°ì‹œ ë³´ë„ìë£Œ"
                    elif field == 'date':
                        metadata[field] = datetime.now().strftime("%Y-%m-%d")
                    elif field == 'tags':
                        metadata[field] = ["ì „ì²´"]
                    elif field == 'thumbnail_summary':
                        metadata[field] = "ë¶€ì‚°ì‹œ ë³´ë„ìë£Œì…ë‹ˆë‹¤."
            
            logger.info(f"âœ… frontmatter íŒŒì‹± ì™„ë£Œ: {list(metadata.keys())}")
            return metadata
            
        except Exception as e:
            logger.error(f"âŒ frontmatter íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    def _enhance_tags(self, gpt_tags: List[str], title: str, content: str) -> List[str]:
        """íƒœê·¸ ê²€ì¦ ë° ê°œì„  (1ê°œë§Œ ì„ íƒ)"""
        try:
            enhanced_tags = []
            text_for_analysis = f"{title} {content}".lower()
            
            # 1. GPTê°€ ì œì•ˆí•œ íƒœê·¸ ì¤‘ ìœ íš¨í•œ ê²ƒ ì„ íƒ
            for tag in gpt_tags:
                if tag in AVAILABLE_TAGS:
                    enhanced_tags.append(tag)
                    logger.info(f"âœ… ìœ íš¨í•œ GPT íƒœê·¸ ì‚¬ìš©: {tag}")
                    break  # ì²« ë²ˆì§¸ ìœ íš¨í•œ íƒœê·¸ë§Œ ì‚¬ìš©
            
            # 2. ìœ íš¨í•œ íƒœê·¸ê°€ ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¶”ë¡ 
            if not enhanced_tags:
                logger.info("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ íƒœê·¸ ì¶”ë¡  ì‹œì‘...")
                
                tag_keywords = {
                    "ì²­ë…„Â·êµìœ¡": ["ì²­ë…„", "êµìœ¡", "í•™êµ", "ëŒ€í•™", "í•™ìƒ", "ì·¨ì—…", "ì§„ë¡œ", "ì¸ì¬"],
                    "ì¼ìë¦¬Â·ê²½ì œ": ["ì¼ìë¦¬", "ê²½ì œ", "ê¸°ì—…", "ì‚°ì—…", "íˆ¬ì", "ì°½ì—…", "ê³ ìš©", "ì·¨ì—…"],
                    "ë³µì§€Â·ê±´ê°•": ["ë³µì§€", "ê±´ê°•", "ì˜ë£Œ", "ë³‘ì›", "ëŒë´„", "ì§€ì›", "ì¹˜ë£Œ", "ë³´ê±´"],
                    "êµí†µÂ·ì£¼ê±°": ["êµí†µ", "ì£¼ê±°", "ì£¼íƒ", "ë²„ìŠ¤", "ì§€í•˜ì² ", "ë„ë¡œ", "ì„ëŒ€", "ì•„íŒŒíŠ¸"],
                    "ë¬¸í™”Â·ì—¬ê°€": ["ë¬¸í™”", "ì—¬ê°€", "ì¶•ì œ", "ê³µì—°", "ì „ì‹œ", "ì˜ˆìˆ ", "ìŒì•…", "ì²´ìœ¡"],
                    "ì•ˆì „Â·í™˜ê²½": ["ì•ˆì „", "í™˜ê²½", "í™”ì¬", "ì¬ë‚œ", "íê¸°ë¬¼", "ì²­ì†Œ", "ì˜¤ì—¼", "ë°©ì¬"],
                    "í–‰ì •Â·ì°¸ì—¬": ["í–‰ì •", "ì°¸ì—¬", "ì‹œë¯¼", "ì •ì±…", "íšŒì˜", "í˜‘ì˜", "ë¯¼ì›", "ì„œë¹„ìŠ¤"],
                    "ê´€ê´‘Â·ì†Œì‹": ["ê´€ê´‘", "ì†Œì‹", "ë°©ë¬¸", "í™ë³´", "ì™¸êµ­ì¸", "êµ­ì œ", "ì—¬í–‰", "ì¶•ì œ"]
                }
                
                tag_scores = {}
                for tag, keywords in tag_keywords.items():
                    score = sum(1 for keyword in keywords if keyword in text_for_analysis)
                    if score > 0:
                        tag_scores[tag] = score
                        logger.debug(f"   {tag}: {score}ì ")
                
                if tag_scores:
                    best_tag = max(tag_scores, key=tag_scores.get)
                    enhanced_tags.append(best_tag)
                    logger.info(f"âœ… í‚¤ì›Œë“œ ê¸°ë°˜ íƒœê·¸ ì„ íƒ: {best_tag} ({tag_scores[best_tag]}ì )")
            
            # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì œëª©ìœ¼ë¡œ ê°„ë‹¨ ì¶”ë¡ 
            if not enhanced_tags:
                logger.info("ğŸ¯ ì œëª© ê¸°ë°˜ íƒœê·¸ ì¶”ë¡ ...")
                
                title_lower = title.lower()
                if any(word in title_lower for word in ["êµìœ¡", "í•™êµ", "ì²­ë…„", "ëŒ€í•™"]):
                    enhanced_tags.append("ì²­ë…„Â·êµìœ¡")
                elif any(word in title_lower for word in ["ê²½ì œ", "ì¼ìë¦¬", "ê¸°ì—…", "ì‚°ì—…"]):
                    enhanced_tags.append("ì¼ìë¦¬Â·ê²½ì œ")
                elif any(word in title_lower for word in ["ë¬¸í™”", "ì¶•ì œ", "ê³µì—°", "ì „ì‹œ"]):
                    enhanced_tags.append("ë¬¸í™”Â·ì—¬ê°€")
                elif any(word in title_lower for word in ["ì•ˆì „", "í™˜ê²½", "í™”ì¬", "ì¬ë‚œ"]):
                    enhanced_tags.append("ì•ˆì „Â·í™˜ê²½")
                elif any(word in title_lower for word in ["êµí†µ", "ì£¼ê±°", "ë²„ìŠ¤", "ì£¼íƒ"]):
                    enhanced_tags.append("êµí†µÂ·ì£¼ê±°")
                elif any(word in title_lower for word in ["ë³µì§€", "ê±´ê°•", "ì˜ë£Œ", "ëŒë´„"]):
                    enhanced_tags.append("ë³µì§€Â·ê±´ê°•")
                elif any(word in title_lower for word in ["ê´€ê´‘", "ë°©ë¬¸", "êµ­ì œ", "ì™¸êµ­"]):
                    enhanced_tags.append("ê´€ê´‘Â·ì†Œì‹")
                else:
                    enhanced_tags.append("í–‰ì •Â·ì°¸ì—¬")  # ê¸°ë³¸ê°’
                
                logger.info(f"âœ… ì œëª© ê¸°ë°˜ íƒœê·¸ ì„ íƒ: {enhanced_tags[0]}")
            
            # 4. ìµœì¢… ê²€ì¦ (1ê°œë§Œ ë°˜í™˜)
            final_tags = enhanced_tags[:1]
            logger.info(f"ğŸ·ï¸ ìµœì¢… íƒœê·¸: {final_tags}")
            return final_tags
            
        except Exception as e:
            logger.error(f"âŒ íƒœê·¸ ê°œì„  ì‹¤íŒ¨: {e}")
            return ["ì „ì²´"]  # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’
    
    def create_filename_from_metadata(self, metadata: Dict) -> str:
        """ë©”íƒ€ë°ì´í„°ë¡œë¶€í„° íŒŒì¼ëª… ìƒì„±"""
        try:
            title = metadata.get('title', 'ë³´ë„ìë£Œ')
            date = metadata.get('date', datetime.now().strftime("%Y-%m-%d"))
            tags = metadata.get('tags', ['ì „ì²´'])
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜: 2025-07-03 â†’ 20250703
            clean_date = date.replace('-', '') if date else datetime.now().strftime("%Y%m%d")
            
            # íƒœê·¸ (ì²« ë²ˆì§¸ë§Œ)
            main_tag = tags[0] if tags else 'ì „ì²´'
            
            # ì œëª© ì •ë¦¬
            clean_title = self._clean_title_for_filename(title)
            
            # íŒŒì¼ëª… ìƒì„±
            filename = f"{clean_date}_{main_tag}_{clean_title}.md"
            
            # íŒŒì¼ëª… ê¸¸ì´ ì œí•œ (Windows íŒŒì¼ëª… ì œí•œ ê³ ë ¤)
            if len(filename) > 100:
                clean_title = clean_title[:50]
                filename = f"{clean_date}_{main_tag}_{clean_title}.md"
            
            logger.info(f"ğŸ“ íŒŒì¼ëª… ìƒì„±: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ íŒŒì¼ëª…
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            return f"{timestamp}_ë³´ë„ìë£Œ.md"
    
    def _clean_title_for_filename(self, title: str) -> str:
        """íŒŒì¼ëª…ìš© ì œëª© ì •ë¦¬"""
        try:
            # 1. íŠ¹ìˆ˜ë¬¸ì ì œê±° (íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì)
            clean_title = re.sub(r'[<>:"/\\|?*\[\]{}]', '', title)
            
            # 2. ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜
            clean_title = re.sub(r'\s+', '_', clean_title.strip())
            
            # 3. ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
            clean_title = re.sub(r'_+', '_', clean_title)
            
            # 4. ì¡°ì‚¬ ì œê±°
            particles = ['ì˜', 'ì„', 'ë¥¼', 'ì—', 'ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì´', 'ê°€', 'ëŠ”', 'ë„']
            words = clean_title.split('_')
            filtered_words = []
            
            for word in words:
                if word and word not in particles and len(word) > 1:
                    filtered_words.append(word)
            
            # 5. ë‹¨ì–´ ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 4ê°œ)
            if len(filtered_words) > 4:
                filtered_words = filtered_words[:4]
            
            clean_title = '_'.join(filtered_words)
            
            # 6. ê¸¸ì´ ì œí•œ (30ì)
            if len(clean_title) > 30:
                clean_title = clean_title[:30]
            
            # 7. ì•ë’¤ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
            clean_title = clean_title.strip('_')
            
            # 8. ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
            if not clean_title:
                clean_title = "ë³´ë„ìë£Œ"
            
            return clean_title
            
        except Exception as e:
            logger.error(f"âŒ ì œëª© ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return "ë³´ë„ìë£Œ"
    
    def save_markdown(self, summary_data: Dict, filename: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥"""
        try:
            filepath = Path(self.output_dir) / filename
            
            # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë°±ì—…
            if filepath.exists():
                backup_path = filepath.with_suffix('.md.bak')
                filepath.rename(backup_path)
                logger.info(f"ğŸ“¦ ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_path.name}")
            
            # ìƒˆ íŒŒì¼ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(summary_data['content'])
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = filepath.stat().st_size
            logger.info(f"âœ… ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥: {filename} ({file_size:,} bytes)")
            
            return str(filepath)
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def _check_md_exists_for_pdf(self, pdf_path: str) -> Optional[str]:
        """PDFì— ëŒ€ì‘í•˜ëŠ” MD íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        try:
            pdf_filename = Path(pdf_path).name
            
            # MD í´ë”ì˜ ëª¨ë“  íŒŒì¼ í™•ì¸
            md_files = list(Path(self.output_dir).glob("*.md"))
            
            for md_file in md_files:
                try:
                    # MD íŒŒì¼ì—ì„œ PDF íŒŒì¼ëª…ê³¼ ì—°ê´€ì„± í™•ì¸
                    # ë°©ë²• 1: íŒŒì¼ëª…ì— PDF ì´ë¦„ í¬í•¨ ì—¬ë¶€ í™•ì¸
                    pdf_base = pdf_filename.replace('.pdf', '')
                    clean_pdf_name = self._clean_title_for_filename(pdf_base)
                    
                    if clean_pdf_name in md_file.name:
                        logger.info(f"ğŸ” ê¸°ì¡´ MD íŒŒì¼ ë°œê²¬ (íŒŒì¼ëª… ë§¤ì¹­): {md_file.name}")
                        return str(md_file)
                    
                    # ë°©ë²• 2: MD íŒŒì¼ ë‚´ìš©ì—ì„œ PDF íŒŒì¼ëª… í™•ì¸ (frontmatter íŒŒì‹±)
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # frontmatterì—ì„œ ì œëª© ì¶”ì¶œí•˜ì—¬ ë¹„êµ
                    if content.startswith('---'):
                        end_idx = content.find('---', 3)
                        if end_idx > 0:
                            frontmatter = content[3:end_idx]
                            for line in frontmatter.split('\n'):
                                if line.strip().startswith('title:'):
                                    title = line.split(':', 1)[1].strip().strip('"\'')
                                    title_clean = self._clean_title_for_filename(title)
                                    
                                    if clean_pdf_name in title_clean or title_clean in clean_pdf_name:
                                        logger.info(f"ğŸ” ê¸°ì¡´ MD íŒŒì¼ ë°œê²¬ (ì œëª© ë§¤ì¹­): {md_file.name}")
                                        return str(md_file)
                                    break
                    
                except Exception as e:
                    logger.debug(f"MD íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {md_file.name} - {e}")
                    continue
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ MD íŒŒì¼ ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None
    
    def process_pdf_file(self, pdf_path: str, source_url: str = "") -> Optional[str]:
        """PDF íŒŒì¼ í•˜ë‚˜ë¥¼ ì²˜ë¦¬í•´ì„œ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        try:
            pdf_filename = Path(pdf_path).name
            logger.info(f"ğŸš€ PDF ì²˜ë¦¬ ì‹œì‘: {pdf_filename}")
            
            # ğŸ”§ ì¤‘ë³µ í™•ì¸ - ì´ë¯¸ ì²˜ë¦¬ëœ PDFì¸ì§€ ì²´í¬
            existing_md = self._check_md_exists_for_pdf(pdf_path)
            if existing_md:
                logger.info(f"â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ PDF ìŠ¤í‚µ: {pdf_filename} â†’ {Path(existing_md).name}")
                return existing_md
            
            # source_url ê¸°ë³¸ê°’ ì„¤ì •
            if not source_url:
                source_url = "https://www.busan.go.kr/nbtnewsBU"
                logger.info("ğŸ“ ê¸°ë³¸ URL ì‚¬ìš©")
            
            # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            content = self.extract_text_from_pdf(pdf_path)
            if not content:
                logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_filename}")
                return None
            
            # 2. GPTë¡œ ìš”ì•½ ìƒì„±
            summary_data = self.generate_summary_with_gpt(content, source_url)
            if not summary_data:
                logger.warning(f"âš ï¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {pdf_filename}")
                return None
            
            # 3. íƒœê·¸ ê°œì„ 
            metadata = summary_data['metadata']
            title = metadata.get('title', pdf_filename)
            gpt_tags = metadata.get('tags', ['ì „ì²´'])
            
            enhanced_tags = self._enhance_tags(gpt_tags, title, content)
            metadata['tags'] = enhanced_tags
            
            # summary_dataì— ê°œì„ ëœ ë©”íƒ€ë°ì´í„° ë°˜ì˜
            summary_data['metadata'] = metadata
            
            # 4. íŒŒì¼ëª… ìƒì„±
            filename = self.create_filename_from_metadata(metadata)
            
            # ğŸ”§ ì¤‘ë³µ í™•ì¸ - ìƒì„±ë  íŒŒì¼ëª…ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ ì²´í¬
            target_filepath = Path(self.output_dir) / filename
            if target_filepath.exists():
                logger.info(f"â­ï¸ ë™ì¼í•œ íŒŒì¼ëª…ì˜ MD íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ìŠ¤í‚µ: {filename}")
                return str(target_filepath)
            
            # 5. ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
            md_path = self.save_markdown(summary_data, filename)
            
            if md_path:
                logger.info(f"ğŸ‰ PDF ì²˜ë¦¬ ì™„ë£Œ: {pdf_filename} â†’ {filename}")
                return md_path
            else:
                logger.warning(f"âš ï¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {pdf_filename}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ {Path(pdf_path).name}: {e}")
            return None
    
    def process_all_pdfs(self, source_urls: Dict[str, str] = None) -> List[str]:
        """ëª¨ë“  PDF íŒŒì¼ì„ ì²˜ë¦¬"""
        try:
            # PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            pdf_files = list(Path(PDF_DIR).glob("*.pdf"))
            
            if not pdf_files:
                logger.warning("âš ï¸ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            logger.info(f"ğŸ“‹ ì²˜ë¦¬í•  PDF íŒŒì¼: {len(pdf_files)}ê°œ")
            
            # ğŸ”§ ì¤‘ë³µ ì œê±° - ì´ë¯¸ ì²˜ë¦¬ëœ PDF í•„í„°ë§
            unprocessed_pdfs = []
            skipped_count = 0
            
            for pdf_path in pdf_files:
                existing_md = self._check_md_exists_for_pdf(str(pdf_path))
                if existing_md:
                    logger.info(f"â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ PDF ìŠ¤í‚µ: {pdf_path.name}")
                    skipped_count += 1
                else:
                    unprocessed_pdfs.append(pdf_path)
            
            if skipped_count > 0:
                logger.info(f"ğŸ“Š ì¤‘ë³µ ì œê±° ê²°ê³¼: {skipped_count}ê°œ ìŠ¤í‚µ, {len(unprocessed_pdfs)}ê°œ ì²˜ë¦¬ ì˜ˆì •")
            
            if not unprocessed_pdfs:
                logger.info("âœ… ëª¨ë“  PDFê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                return []
            
            # URL ë§¤í•‘ ì •ë³´ ì¶œë ¥
            if source_urls:
                logger.info(f"ğŸ”— URL ë§¤í•‘ ì •ë³´: {len(source_urls)}ê°œ")
            else:
                logger.info("ğŸ”— URL ë§¤í•‘ ì—†ìŒ - ê¸°ë³¸ URL ì‚¬ìš©")
            
            generated_files = []
            failed_files = []
            
            for idx, pdf_path in enumerate(unprocessed_pdfs, 1):
                try:
                    logger.info(f"ğŸ“„ ì§„í–‰ìƒí™©: {idx}/{len(unprocessed_pdfs)} - {pdf_path.name}")
                    
                    # URL ë§¤í•‘ì—ì„œ ì°¾ê¸°
                    pdf_filename = pdf_path.name
                    source_url = ""
                    
                    if source_urls and pdf_filename in source_urls:
                        source_url = source_urls[pdf_filename]
                        logger.info(f"ğŸ”— ë§¤í•‘ëœ URL ì‚¬ìš©: {source_url}")
                    
                    # PDF ì²˜ë¦¬
                    md_file = self.process_pdf_file(str(pdf_path), source_url)
                    
                    if md_file:
                        generated_files.append(md_file)
                        logger.info(f"âœ… ì„±ê³µ: {Path(md_file).name}")
                    else:
                        failed_files.append(pdf_filename)
                        logger.warning(f"âŒ ì‹¤íŒ¨: {pdf_filename}")
                    
                    # API ìš”ì²­ ê°„ê²© (Rate Limit ë°©ì§€)
                    if idx < len(unprocessed_pdfs):  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ ëŒ€ê¸°
                        time.sleep(2)
                    
                except Exception as e:
                    logger.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ {pdf_path.name}: {e}")
                    failed_files.append(pdf_path.name)
                    continue
            
            # ê²°ê³¼ ìš”ì•½
            logger.info("="*60)
            logger.info("ğŸ‰ ì „ì²´ PDF ì²˜ë¦¬ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
            logger.info(f"   ğŸ“ ì „ì²´ PDF: {len(pdf_files)}ê°œ")
            logger.info(f"   â­ï¸ ìŠ¤í‚µ (ì¤‘ë³µ): {skipped_count}ê°œ")
            logger.info(f"   âœ… ìƒˆë¡œ ì²˜ë¦¬ ì„±ê³µ: {len(generated_files)}ê°œ")
            logger.info(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {len(failed_files)}ê°œ")
            
            if failed_files:
                logger.info("âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
                for failed_file in failed_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                    logger.info(f"   - {failed_file}")
                if len(failed_files) > 5:
                    logger.info(f"   ... ì™¸ {len(failed_files) - 5}ê°œ")
            
            logger.info("="*60)
            
            return generated_files
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('summarizer_test.log', encoding='utf-8')
        ]
    )
    
    try:
        # ìš”ì•½ê¸° ì´ˆê¸°í™”
        summarizer = BusanNewsSummarizer()
        
        # ëª¨ë“  PDF ì²˜ë¦¬
        results = summarizer.process_all_pdfs()
        
        print(f"\nğŸ¯ ìš”ì•½ ê²°ê³¼: {len(results)}ê°œ íŒŒì¼ ìƒì„±")
        print("ìƒì„±ëœ íŒŒì¼ë“¤:")
        for result in results[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"- {Path(result).name}")
        
        if len(results) > 10:
            print(f"... ì™¸ {len(results) - 10}ê°œ")
    
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)