"""
ë¶€ì‚°ì‹œì²­ ì—…ë¬´ê³„íš ìš”ì•½ê¸° - SimplePlansSummarizer
==============================================
ì—…ë¬´ê³„íš PDF â†’ MD ë³€í™˜ ì „ìš© (ë‹¨ìˆœ ì¼ê´„ ì²˜ë¦¬)

ì£¼ìš” íŠ¹ì§•:
- ì¤‘ë³µ ì²´í¬ ë¶ˆí•„ìš” (29ê°œ ê³ ì •)
- URL ë§¤í•‘ ë¶ˆí•„ìš” (ì›ë¬¸ ë§í¬ ì—†ìŒ)
- ë‹¨ìˆœ PDF â†’ MD ë³€í™˜ë§Œ
- ì¸ë„¤ì¼ ìš”ì•½ì—ì„œ ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ì •ë³´ ì œê±°
"""

import os
import logging
import re
from pathlib import Path
from typing import Dict, Optional, List

import openai
import fitz  # PyMuPDF
from datetime import datetime

from config import (
   OPENAI_API_KEY, OPENAI_MODEL, MAX_TOKENS, TEMPERATURE,
   AVAILABLE_PLAN_TAGS, PLANS_PDF_DIR, PLANS_MD_DIR,
   PLANS_SUMMARY_PROMPT, PLAN_DEPARTMENTS
)

logger = logging.getLogger(__name__)

class SimplePlansSummarizer:
   """ì—…ë¬´ê³„íš ì „ìš© ê°„ë‹¨ ìš”ì•½ê¸°"""
   
   def __init__(self):
       """ì´ˆê¸°í™”"""
       if not OPENAI_API_KEY:
           raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
       
       self.client = openai.OpenAI(api_key=OPENAI_API_KEY)
       self.pdf_dir = PLANS_PDF_DIR
       self.md_dir = PLANS_MD_DIR
       
       # ë””ë ‰í† ë¦¬ ìƒì„±
       Path(self.md_dir).mkdir(parents=True, exist_ok=True)
       
       logger.info("âœ… SimplePlansSummarizer ì´ˆê¸°í™” ì™„ë£Œ")
   
   def extract_text_from_pdf(self, pdf_path: str) -> str:
       """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)"""
       doc = None
       try:
           logger.info(f"ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ: {Path(pdf_path).name}")
           
           if not os.path.exists(pdf_path) or os.path.getsize(pdf_path) < 100:
               logger.error("âŒ PDF íŒŒì¼ ë¬¸ì œ")
               return ""
           
           doc = fitz.open(pdf_path)
           if doc.page_count == 0:
               return ""
           
           # ì²« 5í˜ì´ì§€ë§Œ ì¶”ì¶œ (ì—…ë¬´ê³„íšì€ ë³´í†µ ì•ë¶€ë¶„ì´ ì¤‘ìš”)
           text_parts = []
           max_pages = min(5, doc.page_count)
           
           for page_num in range(max_pages):
               try:
                   page_text = doc[page_num].get_text()
                   if page_text.strip():
                       text_parts.append(page_text)
               except Exception:
                   continue
           
           full_text = "\n".join(text_parts)
           
           # í…ìŠ¤íŠ¸ ì •ë¦¬
           if full_text:
               full_text = re.sub(r'\n\s*\n', '\n\n', full_text)
               full_text = re.sub(r'[ \t]+', ' ', full_text)
               full_text = re.sub(r'\n[ \t]+', '\n', full_text)
               full_text = full_text.strip()
           
           if len(full_text) < 100:
               logger.warning("âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ")
               return ""
           
           logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(full_text)}ì")
           return full_text
           
       except Exception as e:
           logger.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
           return ""
       finally:
           if doc:
               try:
                   doc.close()
               except:
                   pass
   
   def extract_department_from_filename(self, filename: str) -> str:
       """íŒŒì¼ëª…ì—ì„œ ë¶€ì„œëª… ì¶”ì¶œ"""
       try:
           # "2025ë…„ ë¶€ì„œëª… ì£¼ìš”ì—…ë¬´ê³„íš.pdf" í˜•íƒœì—ì„œ ë¶€ì„œëª… ì¶”ì¶œ
           if "ì£¼ìš”ì—…ë¬´ê³„íš" in filename:
               # "2025ë…„ " ì œê±°í•˜ê³  " ì£¼ìš”ì—…ë¬´ê³„íš.pdf" ì œê±°
               dept_part = filename.replace("2025ë…„ ", "").replace(" ì£¼ìš”ì—…ë¬´ê³„íš.pdf", "")
               return dept_part
           
           return "ë¯¸ë¶„ë¥˜"
           
       except Exception as e:
           logger.error(f"ë¶€ì„œëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
           return "ë¯¸ë¶„ë¥˜"
   
   def get_department_category(self, department: str) -> str:
       """ë¶€ì„œëª…ìœ¼ë¡œë¶€í„° ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°"""
       for display_name, dept_list in PLAN_DEPARTMENTS:
           if dept_list != "ì „ì²´" and any(dept in department for dept in dept_list):
               # "ğŸ›ï¸ ê¸°íšê°ì‚¬" -> "ê¸°íšê°ì‚¬" ì¶”ì¶œ
               return display_name.split(' ', 1)[1] if ' ' in display_name else display_name
       
       return "ì „ì²´"
   
   def generate_summary_with_gpt(self, content: str, department: str) -> Optional[Dict]:
       """GPTë¥¼ ì´ìš©í•œ ì—…ë¬´ê³„íš ìš”ì•½ ìƒì„±"""
       try:
           # ë‚´ìš© ê¸¸ì´ ì œí•œ (ì—…ë¬´ê³„íšì€ ê¸¸ ìˆ˜ ìˆìŒ)
           if len(content) > 4000:
               content = content[:4000]
           
           # ë¶€ì„œëª…ìœ¼ë¡œë¶€í„° ë¶„ë¥˜ ì¶”ì¶œ
           category = self.get_department_category(department)
           
           # ì—…ë¬´ê³„íš ì „ìš© GPT í”„ë¡¬í”„íŠ¸ (ì¸ë„¤ì¼ ìš”ì•½ ê°œì„ )
           prompt = f"""
ì•„ë˜ ë¶€ì‚°ì‹œ {department}ì˜ ì—…ë¬´ê³„íšì„ **ì‹œë¯¼ ì„¤ëª…íšŒ ë˜ëŠ” SNS ì¹´ë“œë‰´ìŠ¤**ë¡œ í™œìš©í•  ìˆ˜ ìˆê²Œ
**ì´ëª¨ì§€**, **ì¹´ë“œí˜• ìš”ì•½**, **ê°„ê²°í•˜ê³  ì‹¤ê°ë‚˜ëŠ” ìŠ¤í† ë¦¬í…”ë§**ìœ¼ë¡œ 
í•µì‹¬ë§Œ ë½‘ì•„ **1ë¶„ ì´ë‚´ì— ì½ëŠ” ìˆœê°„ ëª°ì…**ë  ë§Œí¼ êµ¬ì²´ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

**ğŸ“Œ ì ˆëŒ€ ê·œì¹™:**
- ë°˜ë“œì‹œ "ì•„ë˜ ì œê³µëœ PDF í…ìŠ¤íŠ¸"ë§Œ ì°¸ê³ í•˜ì—¬, ì™¸ë¶€ ì •ë³´, ì›¹ ê²€ìƒ‰, ì£¼ê´€ì  í•´ì„, ì¼ë°˜ ìƒì‹, íƒ€ ë¶€ì„œ ì‚¬ì—…, ì¸ìš©/ì°½ì‘, ì¶”ì • ë‚´ìš©ì€ ì ˆëŒ€ ë„£ì§€ ë§ˆì„¸ìš”.
- PDF ë‚´ **ëŒ€ë¶„ë¥˜ ì œëª©(1/, 2/, 3/, 4/, 5/, 6/ ë“±)**ì„ ë°˜ë“œì‹œ ì¹´ë“œ ì œëª©ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- ê° ëŒ€ë¶„ë¥˜ í•˜ìœ„ì˜ **êµ¬ì²´ì  ì‚¬ì—…ëª…ê³¼ ì‹¤ì œ ë‚´ìš©**ì„ ì¹´ë“œë³„ë¡œ êµ¬ì–´ì²´ë¡œ ìš”ì•½í•˜ì„¸ìš”.
- "ì§€ì›í•©ë‹ˆë‹¤/ê³„íší•©ë‹ˆë‹¤" ëŒ€ì‹  **ì‹¤ì œ ì‚¬ì—…ëª…ì„ ì—°ê²°í•´ì„œ** ì‹œë¯¼ë“¤ì´ ë¬´ì—‡ì´ ì–´ë–»ê²Œ ë°”ë€ŒëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
- ì‹¤ì œ PDF ë‚´ ìˆ˜ì¹˜, ì •ì±…, ì‚¬ì—…ëª…, ì„±ê³¼, ê³„íš, íŠ¹ì´ì  ë“± **ëª…í™•í•˜ê²Œ ëª…ì‹œëœ ì •ë³´**ë§Œ ì¹´ë“œë³„ë¡œ ìš”ì•½í•˜ì„¸ìš”.

**[ëª©í‘œ]**
ì‹œë¯¼ì„¤ëª…íšŒ/SNS ì¹´ë“œë‰´ìŠ¤ ìŠ¤íƒ€ì¼ë¡œ, **1ë¶„ ì´ë‚´ì— í•µì‹¬ë§Œ ì‹¤ê°ë‚˜ê²Œ ì¹´ë“œ í˜•íƒœë¡œ ìš”ì•½**  
(ë¶ˆí•„ìš”í•œ ë°°ê²½ì„¤ëª…Â·ë„ì…ë¶€Â·ë§ºìŒë§Â·PDFì— ì—†ëŠ” ë‚´ìš© ì œì™¸)

PDFì˜ ëŒ€ë¶„ë¥˜ ì œëª©ì„ ê·¸ëŒ€ë¡œ í™œìš©í•´ì„œ ê° ì œëª©ë³„ë¡œ ì‹¤ì œ ì¶”ì§„ë˜ëŠ” ì‚¬ì—…ë“¤ì„ 
ì‹œë¯¼ë“¤ì´ "ì•„, ì´ëŸ° ê²Œ ë°”ë€ŒëŠ”êµ¬ë‚˜!" í•˜ê³  ì²´ê°í•  ìˆ˜ ìˆê²Œ ì¹´ë“œë³„ë¡œ ìš”ì•½

ê° ì¹´ë“œëŠ”
"ì´ëª¨ì§€ + ëŒ€ë¶„ë¥˜ ì œëª©" 

ì„¸ë¶€ë‚´ìš©ì€ **êµ¬ì–´ì²´**ë¡œ ì‚¬ì—…ë“¤ì„ ì—°ê²°í•´ì„œ ì„¤ëª…
"~í•©ë‹ˆë‹¤", "~í•´ìš”", "~ëŠ˜ë ¤ìš”", "~ì¶”ì§„!" ê°™ì´
ë”±ë”±í•˜ì§€ ì•Šê³  ì¹œê·¼í•˜ê²Œ ë§ˆë¬´ë¦¬

âŒ ë‚˜ìœ ì˜ˆ: "ë¶€ì‚°ì´ ë°œì „í•´ìš”"
âœ… ì¢‹ì€ ì˜ˆ: "ê¸€ë¡œë²Œí—ˆë¸Œë„ì‹œ íŠ¹ë³„ë²•ìœ¼ë¡œ ë¬¼ë¥˜Â·ê¸ˆìœµÂ·ì²¨ë‹¨ì‚°ì—… ê±°ì ì„ ë§Œë“¤ê³ , ì‹œë¯¼í–‰ë³µë¶€ì‚°íšŒì˜ì—ì„œ ìƒí™œ ì† ì˜ê²¬ì„ ì§ì ‘ ì‹œì •ì— ë°˜ì˜í•´ìš”"

ì‚¬ì—…ëª…ì´ë‚˜ ìˆ˜ì¹˜ ë¨¼ì € ì“°ê³ , ì„¸ë¶€ë‚´ìš©ì€ ì‹¤ì œ PDFì— ëª…ì‹œëœ ê²ƒë§Œ ì‚¬ìš©í•´ì„œ
ì¹œê·¼í•œ êµ¬ì–´ì²´ë¡œ ì—°ê²°í•´ì„œ ì„¤ëª…

ë³¼ë“œì²´ëŠ” ìˆ«ìë‚˜ ì§„ì§œ ì¤‘ìš”í•œ ì‚¬ì—…ëª…ì—ë§Œ

PDFì— ì§„ì§œ ìˆëŠ” ë‚´ìš©ë§Œí¼ë§Œ ì¹´ë“œ ê°œìˆ˜ ì¡°ì •
ì—†ëŠ” ê±´ ì–µì§€ë¡œ ì±„ìš°ì§€ ë§ê³ ,
"ìˆëŠ” ì •ë³´ë§Œ, ì‹œë¯¼ ëˆˆë†’ì´ì— ë§ê²Œ, ê°€ë³ê²Œ!"

ì¶”ê°€ ì„¤ëª…, ì•ˆë‚´ë¬¸, ì¶”ì •, ì™¸ë¶€ ì˜ˆì‹œ, ë°˜ë³µ ë©˜íŠ¸,
ë»”í•œ ê´€ë£Œì²´ëŠ” ì•„ì˜ˆ ê¸ˆì§€!

---
ì•„ë˜ì˜ ë§ˆí¬ë‹¤ìš´ frontmatter í˜•ì‹ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì¶œë ¥í•  ê²ƒ:
---
title: "{department} 2025ë…„ ì£¼ìš”ì—…ë¬´ê³„íš"
date: "2025"
tags: ["{category}"]
thumbnail_summary: "ì‹œë¯¼ì´ ì²´ê°í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ë³€í™”ë‚˜ ì„±ê³¼ë¥¼ 80ì ì´ë‚´ë¡œ ìš”ì•½ (ì—°ë„ë‚˜ ì§€ì—­ëª… ì¤‘ë³µ ì œê±°)"
department: "{department}"
---

**thumbnail_summary ì‘ì„± ê°€ì´ë“œ:**
- âŒ ë‚˜ìœ ì˜ˆ: "2025ë…„ ë¶€ì‚° ê´€ê´‘ê° 300ë§Œ ì‹œëŒ€ ë„ì•½"
- âœ… ì¢‹ì€ ì˜ˆ: "ì™¸êµ­ì¸ ê´€ê´‘ê° 300ë§Œ ì‹œëŒ€! ì¶•ì œÂ·ë¯¸ì‹Â·í¬ë£¨ì¦ˆ í™•ëŒ€ë¡œ ì²´ê°í•˜ëŠ” ë³€í™”"
- âŒ ë‚˜ìœ ì˜ˆ: "2025ë…„ ë¶€ì‚°ì‹œ êµí†µí˜ì‹  ì¶”ì§„ê³„íš"  
- âœ… ì¢‹ì€ ì˜ˆ: "ëŒ€ì¤‘êµí†µ 30% ë‹¨ì¶•, ìŠ¤ë§ˆíŠ¸ ì‹ í˜¸ë“±ìœ¼ë¡œ êµí†µì²´ì¦ í•´ê²°"
- **í•µì‹¬ì€ ì‹œë¯¼ì´ ì§ì ‘ ëŠë‚„ ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë³€í™”ë‚˜ ìˆ˜ì¹˜ë¥¼ í¬í•¨**

ë¶€ì‚°ì‹œ {department} ì—…ë¬´ê³„íš ì „ë¬¸:
{content}
---

**ìœ„ ë‚´ìš©ë§Œ ì°¸ê³ í•´ì„œ, "ì‹œë¯¼ì´ ì§„ì§œ ì²´ê°í•˜ëŠ” ë³€í™”"ë¥¼  
ì¹´ë“œë‰´ìŠ¤/ì„¤ëª…íšŒ ìŠ¤íƒ€ì¼ë¡œ 1ë¶„ ë‚´ì— ëª°ì…í•  ìˆ˜ ìˆê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.**

ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ë¥˜: {', '.join(AVAILABLE_PLAN_TAGS)}
ë¶„ë¥˜ëŠ” ë¶€ì„œ ì„±ê²©ì— ê°€ì¥ ì í•©í•œ **1ê°œë§Œ** ì„ íƒí•˜ì„¸ìš”.

**ë¶„ë¥˜ ê°€ì´ë“œë¼ì¸:**
- ê¸°íšê°ì‚¬: ë¶€ì‚°ê´‘ì—­ì‹œ, ê¸°íšê´€, ê¸°íšì¡°ì •ì‹¤, ëŒ€ë³€ì¸ì‹¤, ê°ì‚¬ìœ„ì›íšŒ
- ë³µì§€ì•ˆì „: ì‹œë¯¼ì•ˆì „ì‹¤, ì‚¬íšŒë³µì§€êµ­, ì‹œë¯¼ê±´ê°•êµ­, ì—¬ì„±ê°€ì¡±êµ­, ìì¹˜ê²½ì°°ìœ„ì›íšŒ
- ê±´ì„¤êµí†µ: ë„ì‹œí˜ì‹ ê· í˜•ì‹¤, ë„ì‹œê³µê°„ê³„íšêµ­, ì£¼íƒê±´ì¶•êµ­, ì‹ ê³µí•­ì¶”ì§„ë³¸ë¶€, êµí†µí˜ì‹ êµ­, ê±´ì„¤ë³¸ë¶€
- ë„ì‹œí™˜ê²½: í™˜ê²½ë¬¼ì •ì±…ì‹¤, í‘¸ë¥¸ë„ì‹œêµ­, ë³´ê±´í™˜ê²½ì—°êµ¬ì›, ë‚™ë™ê°•ê´€ë¦¬ë³¸ë¶€, ìƒìˆ˜ë„ì‚¬ì—…ë³¸ë¶€
- ê²½ì œì‚°ì—…: ë””ì§€í„¸ê²½ì œì‹¤, ê¸ˆìœµì°½ì—…ì •ì±…ê´€, ì²¨ë‹¨ì‚°ì—…êµ­, í•´ì–‘ë†ìˆ˜ì‚°êµ­
- ë¬¸í™”êµìœ¡: ë¬¸í™”ì²´ìœ¡êµ­, ê´€ê´‘ë§ˆì´ìŠ¤êµ­, ì²­ë…„ì‚°í•™êµ­, ì¸ì¬ê°œë°œì›

ë°˜ë“œì‹œ ---ë¡œ ê°ì‹¸ì§„ frontmatter í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”.
"""
           
           logger.info(f"ğŸ¤– GPT ìš”ì•½ ìƒì„± ì¤‘... ({department})")
           
           response = self.client.chat.completions.create(
               model=OPENAI_MODEL,
               messages=[
                   {
                       "role": "system", 
                       "content": """ë¶€ì‚°ì‹œì²­ ì—…ë¬´ê³„íš ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì¶”ê°€ ì—„ìˆ˜ì‚¬í•­**
- PDFì—ì„œ '2025ë…„ ì£¼ìš”ì—…ë¬´ê³„íš' ì´í•˜ ê° **ëŒ€ë¶„ë¥˜ ì œëª©(1/, 2/, 3/, 4/, 5/, 6/ ë“±)**ëŠ” ë°˜ë“œì‹œ ì¹´ë“œ ì œëª©ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- ì¹´ë“œ ë³¸ë¬¸ì—ëŠ” í•´ë‹¹ ë¶„ë¥˜ ë°”ë¡œ ì•„ë˜ ì‹¤ì œë¡œ í‘œê¸°ëœ **ì •ì±…ëª…, ì‚¬ì—…ëª…, ìˆ˜ì¹˜, ì˜ˆì‚°, ì„±ê³¼**ë§Œ ë‹´ì•„ì£¼ì„¸ìš”.
- ê° ì¹´ë“œëŠ” "ì´ëª¨ì§€ + ëŒ€ë¶„ë¥˜ ì œëª©" êµ¬ì¡°, ì„¸ë¶€ë‚´ìš©ì€ ëª¨ë‘ êµ¬ì–´ì²´ë¡œ ì‚¬ì—…ë“¤ì„ ì—°ê²°í•´ì„œ ì„¤ëª….
- ë¶„ë¥˜ëª… ì•„ë˜ êµ¬ì²´ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì¹´ë“œëŠ” ìƒëµí•©ë‹ˆë‹¤.
- ë°˜ë“œì‹œ ì‹¤ì œ PDF ë‚´ "ëŒ€ë¶„ë¥˜" ê¸°ì¤€ìœ¼ë¡œ ì¹´ë“œ ê°œìˆ˜ë¥¼ ë§ì¶°ì£¼ì„¸ìš”.
- ì¶”ì •, ì°½ì‘, íƒ€ ì„¹ì…˜ ì‚¬ì—…ëª…, ì¶”ê°€ ë¯¸ì‚¬ì—¬êµ¬, ë°˜ë³µÂ·ë„ì…Â·ë§ºìŒë§, AI ì•ˆë‚´ëŠ” ì¼ì ˆ ë„£ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì‹¤ìš©ì„±ê³¼ ê°€ë…ì„±ì„ ì¤‘ì‹œí•˜ì—¬ ì‘ì—…í•˜ì„¸ìš”."""
                   },
                   {"role": "user", "content": prompt}
               ],
               max_tokens=MAX_TOKENS,
               temperature=TEMPERATURE
           )
           
           summary_text = response.choices[0].message.content.strip()
           if not summary_text:
               return None
           
           # frontmatter íŒŒì‹±
           metadata = self._parse_frontmatter(summary_text)
           if not metadata:
               return None
           
           # íƒœê·¸ ê²€ì¦ (ë¶€ì„œëª… ê¸°ë°˜ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë¶„ë¥˜ì¸ì§€ í™•ì¸)
           expected_category = self.get_department_category(department)
           if metadata.get('tags', []) != [expected_category]:
               logger.warning(f"âš ï¸ GPT ë¶„ë¥˜ ìˆ˜ì •: {metadata.get('tags')} â†’ [{expected_category}]")
               metadata['tags'] = [expected_category]
               # ìš”ì•½ í…ìŠ¤íŠ¸ë„ ìˆ˜ì •
               summary_text = re.sub(
                   r'tags: \[.*?\]', 
                   f'tags: ["{expected_category}"]', 
                   summary_text
               )
           
           logger.info(f"âœ… GPT ìš”ì•½ ìƒì„± ì™„ë£Œ (ë¶„ë¥˜: {expected_category})")
           return {
               'metadata': metadata,
               'content': summary_text
           }
               
       except Exception as e:
           logger.error(f"âŒ GPT ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
           return None
   
   def _parse_frontmatter(self, content: str) -> Optional[Dict]:
       """frontmatter íŒŒì‹±"""
       try:
           if not content.startswith('---'):
               return None
           
           end_idx = content.find('---', 3)
           if end_idx == -1:
               return None
           
           frontmatter_text = content[3:end_idx].strip()
           metadata = {}
           
           for line in frontmatter_text.split('\n'):
               line = line.strip()
               if not line or ':' not in line:
                   continue
               
               key, value = line.split(':', 1)
               key = key.strip()
               value = value.strip().strip('"\'')
               
               if key == 'tags':
                   if value.startswith('[') and value.endswith(']'):
                       tag_content = value[1:-1].strip()
                       if tag_content:
                           tags = [tag.strip().strip('"\'') for tag in tag_content.split(',') if tag.strip()]
                           metadata[key] = tags if tags else ["ì „ì²´"]
                       else:
                           metadata[key] = ["ì „ì²´"]
                   else:
                       metadata[key] = [value] if value else ["ì „ì²´"]
               else:
                   metadata[key] = value
           
           # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’
           if 'title' not in metadata:
               metadata['title'] = "ì—…ë¬´ê³„íš"
           if 'date' not in metadata:
               metadata['date'] = "2025-01-01"
           if 'tags' not in metadata:
               metadata['tags'] = ["ì „ì²´"]
           if 'department' not in metadata:
               metadata['department'] = "ë¯¸ë¶„ë¥˜"
           if 'thumbnail_summary' not in metadata:
               metadata['thumbnail_summary'] = "ì£¼ìš”ì—…ë¬´ê³„íš ìš”ì•½ì…ë‹ˆë‹¤."
           
           return metadata
           
       except Exception as e:
           logger.error(f"âŒ frontmatter íŒŒì‹± ì‹¤íŒ¨: {e}")
           return None
   
   def create_filename_from_metadata(self, metadata: Dict, original_filename: str) -> str:
       """ë©”íƒ€ë°ì´í„°ë¡œë¶€í„° íŒŒì¼ëª… ìƒì„±"""
       try:
           department = metadata.get('department', 'ë¯¸ë¶„ë¥˜')
           category = metadata.get('tags', ['ì „ì²´'])[0]
           
           # ê°„ë‹¨í•œ íŒŒì¼ëª…: 2025ë…„_ë¶€ì„œëª…_ì—…ë¬´ê³„íš.md
           clean_dept = re.sub(r'[<>:"/\\|?*\[\]{}]', '', department)
           filename = f"2025ë…„_{clean_dept}_ì—…ë¬´ê³„íš.md"
           
           return filename
           
       except Exception as e:
           logger.error(f"âŒ íŒŒì¼ëª… ìƒì„± ì‹¤íŒ¨: {e}")
           # ì›ë³¸ íŒŒì¼ëª… ê¸°ë°˜ ëŒ€ì•ˆ
           base_name = Path(original_filename).stem
           return f"{base_name}_ìš”ì•½.md"
   
   def save_markdown(self, summary_data: Dict, filename: str) -> str:
       """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥"""
       try:
           filepath = Path(self.md_dir) / filename
           
           with open(filepath, 'w', encoding='utf-8') as f:
               f.write(summary_data['content'])
           
           logger.info(f"âœ… ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥: {filename}")
           return str(filepath)
           
       except Exception as e:
           logger.error(f"âŒ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
           return ""
   
   def process_single_pdf(self, pdf_path: str) -> Optional[str]:
       """ë‹¨ì¼ PDF íŒŒì¼ ì²˜ë¦¬"""
       try:
           pdf_filename = Path(pdf_path).name
           logger.info(f"ğŸš€ ì—…ë¬´ê³„íš PDF ì²˜ë¦¬: {pdf_filename}")
           
           # 1. ë¶€ì„œëª… ì¶”ì¶œ
           department = self.extract_department_from_filename(pdf_filename)
           logger.info(f"ğŸ›ï¸ ë‹´ë‹¹ë¶€ì„œ: {department}")
           
           # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
           content = self.extract_text_from_pdf(pdf_path)
           if not content:
               logger.error(f"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_filename}")
               return None
           
           # 3. GPT ìš”ì•½
           summary_data = self.generate_summary_with_gpt(content, department)
           if not summary_data:
               logger.error(f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨: {pdf_filename}")
               return None
           
           # 4. íŒŒì¼ëª… ìƒì„± ë° ì €ì¥
           metadata = summary_data['metadata']
           filename = self.create_filename_from_metadata(metadata, pdf_filename)
           
           md_path = self.save_markdown(summary_data, filename)
           
           if md_path:
               category = metadata.get('tags', ['ë¯¸ë¶„ë¥˜'])[0]
               logger.info(f"ğŸ‰ ì™„ë£Œ: {pdf_filename} â†’ {filename} (ë¶„ë¥˜: {category})")
               return md_path
           
           return None
               
       except Exception as e:
           logger.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ {Path(pdf_path).name}: {e}")
           return None
   
   def process_all_pdfs(self) -> List[str]:
       """ëª¨ë“  ì—…ë¬´ê³„íš PDF íŒŒì¼ ì²˜ë¦¬"""
       try:
           pdf_files = list(Path(self.pdf_dir).glob("*.pdf"))
           if not pdf_files:
               logger.warning("âš ï¸ ì²˜ë¦¬í•  ì—…ë¬´ê³„íš PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
               return []
           
           logger.info(f"ğŸ“‹ ì²˜ë¦¬í•  ì—…ë¬´ê³„íš PDF: {len(pdf_files)}ê°œ")
           
           generated_files = []
           for idx, pdf_path in enumerate(pdf_files, 1):
               logger.info(f"ğŸ“„ [{idx}/{len(pdf_files)}] {pdf_path.name}")
               
               md_file = self.process_single_pdf(str(pdf_path))
               if md_file:
                   generated_files.append(md_file)
               
               # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
               if idx < len(pdf_files):
                   logger.info("â±ï¸ API ì œí•œ ë°©ì§€ ëŒ€ê¸° (3ì´ˆ)...")
                   time.sleep(3)
           
           logger.info(f"ğŸ‰ ì—…ë¬´ê³„íš ì²˜ë¦¬ ì™„ë£Œ: {len(generated_files)}ê°œ ìƒì„±")
           return generated_files
           
       except Exception as e:
           logger.error(f"âŒ ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
           return []


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_plans_summarizer():
   """ì—…ë¬´ê³„íš ìš”ì•½ê¸° í…ŒìŠ¤íŠ¸"""
   print("ğŸ§ª ì—…ë¬´ê³„íš ìš”ì•½ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
   
   try:
       summarizer = SimplePlansSummarizer()
       
       # í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ í™•ì¸
       test_files = list(Path(summarizer.pdf_dir).glob("*.pdf"))
       print(f"ğŸ“ ë°œê²¬ëœ PDF íŒŒì¼: {len(test_files)}ê°œ")
       
       if test_files:
           # ì²« ë²ˆì§¸ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
           test_file = test_files[0]
           print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_file.name}")
           
           result = summarizer.process_single_pdf(str(test_file))
           if result:
               print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: {result}")
           else:
               print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
       else:
           print("âš ï¸ í…ŒìŠ¤íŠ¸í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
           print(f"   PDF íŒŒì¼ì„ ë‹¤ìŒ ê²½ë¡œì— ë°°ì¹˜í•˜ì„¸ìš”: {summarizer.pdf_dir}")
   
   except Exception as e:
       print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
   import time
   test_plans_summarizer()