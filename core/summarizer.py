"""
ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œ ìš”ì•½ê¸° - BusanNewsSummarizer (ê°œì„ ëœ OCR ì—°ë½ì²˜ ì¶”ì¶œ + ì¤‘ë³µ ì²´í¬)
================================================================
PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ OCRë¡œ ì—°ë½ì²˜ ì¶”ì¶œ â†’ GPTë¡œ ìš”ì•½ â†’ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
"""

import os
import logging
import time
import re
import io
from pathlib import Path
from typing import Dict, List, Optional
import openai
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
from datetime import datetime

from config import (
    OPENAI_API_KEY, OPENAI_MODEL, MAX_TOKENS, TEMPERATURE,
    AVAILABLE_TAGS, MD_DIR, PDF_DIR
)

logger = logging.getLogger(__name__)

class BusanNewsSummarizer:
    """ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œ ìš”ì•½ê¸° (ê°œì„ ëœ OCR ì—°ë½ì²˜ ì¶”ì¶œ + ì¤‘ë³µ ì²´í¬)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        if not OPENAI_API_KEY:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = openai.OpenAI(api_key=OPENAI_API_KEY)
        self.output_dir = MD_DIR
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
        # Tesseract ê²½ë¡œ ì„¤ì •
        self._setup_tesseract()
        
        logger.info("âœ… BusanNewsSummarizer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_tesseract(self):
        """Tesseract OCR ì„¤ì •"""
        possible_paths = [
            r'C:\Program Files\Tesseract-OCR\tesseract.exe',
            r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                pytesseract.pytesseract.tesseract_cmd = path
                logger.info(f"âœ… Tesseract ì„¤ì •: {path}")
                return
        
        logger.warning("âš ï¸ Tesseract ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OCR ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    def check_existing_md_for_pdf(self, pdf_filename: str) -> Optional[str]:
        """ğŸ”§ ê°™ì€ PDFì—ì„œ ìƒì„±ëœ ê¸°ì¡´ MD íŒŒì¼ì´ ìˆëŠ”ì§€ ì²´í¬"""
        try:
            md_files = list(Path(self.output_dir).glob("*.md"))
            
            for md_file in md_files:
                try:
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # frontmatterì—ì„œ source_pdf í•„ë“œ ì°¾ê¸°
                    if content.startswith('---'):
                        frontmatter_end = content.find('---', 3)
                        if frontmatter_end > 0:
                            frontmatter = content[3:frontmatter_end]
                            if f'source_pdf: "{pdf_filename}"' in frontmatter:
                                logger.info(f"â­ï¸ ê¸°ì¡´ MD íŒŒì¼ ë°œê²¬: {md_file.name} (PDF: {pdf_filename})")
                                return str(md_file)
                
                except Exception as e:
                    logger.debug(f"MD íŒŒì¼ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {md_file.name} - {e}")
                    continue
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ì¡´ MD íŒŒì¼ ì²´í¬ ì‹¤íŒ¨: {e}")
            return None
    
    def extract_contact_with_ocr(self, pdf_path: str) -> str:
        """ğŸ”§ ê°œì„ ëœ OCR ì—°ë½ì²˜ ì¶”ì¶œ"""
        try:
            doc = fitz.open(pdf_path)
            page = doc[0]  # ì²« í˜ì´ì§€ë§Œ
            
            # ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë³€í™˜
            mat = fitz.Matrix(4, 4)  # 4ë°° í™•ëŒ€
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            
            # OCR ì‹¤í–‰ (í•œêµ­ì–´ + ì˜ì–´)
            ocr_text = pytesseract.image_to_string(img, lang='kor+eng')
            doc.close()
            
            logger.info(f"ğŸ“‹ OCR ì¶”ì¶œ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {ocr_text[:200]}...")
            
            # ğŸ”§ 1ë‹¨ê³„: ë¶€ì„œëª… ì¶”ì¶œ (ë‹¤ì–‘í•œ íŒ¨í„´ ëŒ€ì‘)
            dept_name = self._extract_department_name(ocr_text)
            
            # ğŸ”§ 2ë‹¨ê³„: ì—°ë½ì²˜ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ë³„)
            phone_number = self._extract_phone_number(ocr_text)
            
            if phone_number:
                result = f"{dept_name} (051-888-{phone_number})"
                logger.info(f"âœ… OCR ì—°ë½ì²˜ ì¶”ì¶œ ì„±ê³µ: {result}")
                return result
            
            # ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
            logger.warning("âš ï¸ OCRì—ì„œ ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return f"{dept_name} ë¬¸ì˜"
            
        except Exception as e:
            logger.error(f"âŒ OCR ì—°ë½ì²˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "í•´ë‹¹ ë¶€ì„œ ë¬¸ì˜"
    
    def _extract_department_name(self, ocr_text: str) -> str:
        """ë¶€ì„œëª… ì¶”ì¶œ (ê³¼, ë‹´ë‹¹ê´€ ìš°ì„  ì„ íƒ)"""
        try:
            # íŒ¨í„´ 1: ë‹´ë‹¹ë¶€ì„œ : ë°”ë¡œ ë‹¤ìŒ ì²« ë²ˆì§¸ ë¶€ì„œë§Œ (ê³¼ ìš°ì„ )
            pattern1 = r'ë‹´ë‹¹ë¶€ì„œ\s*:\s*([ê°€-í£\d]+ê³¼)'
            match1 = re.search(pattern1, ocr_text)
            if match1:
                return match1.group(1)
            
            # íŒ¨í„´ 2: ë‹´ë‹¹ë¶€ì„œ : ë°”ë¡œ ë‹¤ìŒ ì²« ë²ˆì§¸ ë¶€ì„œë§Œ (ë‹´ë‹¹ê´€ ìš°ì„ )
            pattern2 = r'ë‹´ë‹¹ë¶€ì„œ\s*:\s*([ê°€-í£\d]+ê´€)'
            match2 = re.search(pattern2, ocr_text)
            if match2:
                return match2.group(1)
            
            # íŒ¨í„´ 3: ë‹´ë‹¹ë¶€ì„œ ë‹¤ìŒ ì¤„ì—ì„œ ì²« ë²ˆì§¸ ë¶€ì„œë§Œ
            lines = ocr_text.split('\n')
            for i, line in enumerate(lines):
                if 'ë‹´ë‹¹ë¶€ì„œ' in line and i + 1 < len(lines):
                    next_line = lines[i + 1]
                    # ê³¼, ë‹´ë‹¹ê´€ ìš°ì„  ì°¾ê¸°
                    dept_match = re.search(r'([ê°€-í£\d]+ê³¼|[ê°€-í£\d]+ê´€)', next_line)
                    if dept_match:
                        return dept_match.group(1)
                    # ê³¼, ë‹´ë‹¹ê´€ì´ ì—†ìœ¼ë©´ íŒ€
                    team_match = re.search(r'([ê°€-í£\d]+íŒ€)', next_line)
                    if team_match:
                        return team_match.group(1)
            
            return "í•´ë‹¹ ë¶€ì„œ"
            
        except Exception as e:
            logger.error(f"âŒ ë¶€ì„œëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "í•´ë‹¹ ë¶€ì„œ"
    
    def _extract_phone_number(self, ocr_text: str) -> Optional[str]:
        """ì—°ë½ì²˜ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ë³„ íŒ¨í„´)"""
        try:
            # ğŸ”§ ìš°ì„ ìˆœìœ„ 1: ë‹´ë‹¹ì + ì „í™”ë²ˆí˜¸ ì§ì ‘ ë§¤ì¹­
            patterns = [
                # ë‹´ë‹¹ì ì´ë¦„ê³¼ ì „í™”ë²ˆí˜¸ ë§¤ì¹­
                r'ë‹´ë‹¹ì\s+([ê°€-í£]{2,4})\s+051[-.\s]*888[-.\s]*(\d{4})',
                # ë‹´ë‹¹ì ë¼ì¸ì˜ ì „í™”ë²ˆí˜¸
                r'ë‹´ë‹¹ì.*?051[-.\s]*888[-.\s]*(\d{4})',
                # í…Œì´ë¸” í˜•íƒœì—ì„œ ë‹´ë‹¹ì í–‰ì˜ ë²ˆí˜¸
                r'ë‹´ë‹¹ì\s*([ê°€-í£\s]*)\s*051[-.\s]*888[-.\s]*(\d{4})',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, ocr_text)
                if matches:
                    # ë§ˆì§€ë§‰ ê·¸ë£¹ì´ ì „í™”ë²ˆí˜¸
                    phone = matches[0][-1] if isinstance(matches[0], tuple) else matches[0]
                    logger.info(f"âœ… ë‹´ë‹¹ì ì „í™”ë²ˆí˜¸ íŒ¨í„´ ë§¤ì¹­: {phone}")
                    return phone
            
            # ğŸ”§ ìš°ì„ ìˆœìœ„ 2: í…Œì´ë¸” êµ¬ì¡°ì—ì„œ ë§ˆì§€ë§‰ ì¤„ (ë³´í†µ ë‹´ë‹¹ì)
            lines = ocr_text.split('\n')
            phone_lines = []
            for line in lines:
                if '051-888-' in line or '051.888.' in line or '051 888 ' in line:
                    phone_match = re.search(r'051[-.\s]*888[-.\s]*(\d{4})', line)
                    if phone_match:
                        phone_lines.append((line, phone_match.group(1)))
            
            if phone_lines:
                # ë‹´ë‹¹ìê°€ í¬í•¨ëœ ë¼ì¸ ìš°ì„ 
                for line, phone in phone_lines:
                    if 'ë‹´ë‹¹ì' in line:
                        logger.info(f"âœ… ë‹´ë‹¹ì ë¼ì¸ ë§¤ì¹­: {phone}")
                        return phone
                
                # ë‹´ë‹¹ìê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë²ˆí˜¸ (í…Œì´ë¸” êµ¬ì¡°ìƒ ë³´í†µ ë‹´ë‹¹ì)
                logger.info(f"âœ… ë§ˆì§€ë§‰ ì „í™”ë²ˆí˜¸ ì„ íƒ: {phone_lines[-1][1]}")
                return phone_lines[-1][1]
            
            # ğŸ”§ ìš°ì„ ìˆœìœ„ 3: ì²« ë²ˆì§¸ 051-888 ë²ˆí˜¸
            general_pattern = r'051[-.\s]*888[-.\s]*(\d{4})'
            general_matches = re.findall(general_pattern, ocr_text)
            if general_matches:
                logger.info(f"âœ… ì²« ë²ˆì§¸ ì „í™”ë²ˆí˜¸ ì‚¬ìš©: {general_matches[0]}")
                return general_matches[0]
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ ì—°ë½ì²˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        doc = None
        try:
            logger.info(f"ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ: {Path(pdf_path).name}")
            
            if not os.path.exists(pdf_path) or os.path.getsize(pdf_path) < 100:
                logger.error("âŒ PDF íŒŒì¼ ë¬¸ì œ")
                return ""
            
            doc = fitz.open(pdf_path)
            if doc.page_count == 0:
                return ""
            
            text_parts = []
            for page_num in range(doc.page_count):
                try:
                    page_text = doc[page_num].get_text()
                    if page_text.strip():
                        text_parts.append(page_text)
                except Exception:
                    continue
            
            full_text = "\n".join(text_parts)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            if full_text:
                full_text = re.sub(r'\n\s*\n', '\n\n', full_text)
                full_text = re.sub(r'[ \t]+', ' ', full_text)
                full_text = re.sub(r'\n[ \t]+', '\n', full_text)
                full_text = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,()[\]{}!?%-]', '', full_text)
                full_text = full_text.strip()
            
            if len(full_text) < 50:
                logger.warning("âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ")
                return ""
            
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(full_text)}ì")
            return full_text
            
        except Exception as e:
            logger.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
        finally:
            if doc:
                try:
                    doc.close()
                except:
                    pass

    def generate_summary_with_gpt(self, content: str, source_url: str = "", pdf_filename: str = "") -> Optional[Dict]:
        """ğŸ”§ GPTë¥¼ ì´ìš©í•œ ìš”ì•½ ìƒì„± (source_pdf í•„ë“œ ì¶”ê°€)"""
        try:
            # ë‚´ìš© ê¸¸ì´ ì œí•œ
            if len(content) > 3000:
                content = content[:3000]
            
            # source_url ê¸°ë³¸ê°’
            if not source_url:
                source_url = "https://www.busan.go.kr/nbtnewsBU"
            
            # GPT í”„ë¡¬í”„íŠ¸ (ì—°ë½ì²˜ëŠ” ë³„ë„ ì²˜ë¦¬, source_pdf ì¶”ê°€)
            prompt = f"""
ë‹¤ìŒ ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„¸íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.

**ğŸš¨ ì ˆëŒ€ ì›ì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜!):**
1. **PDF ì›ë¬¸ì˜ ëª¨ë“  ë‚´ìš©ì„ ì •í™•íˆ ì½ê³  ì´í•´í•˜ì„¸ìš”**
2. **ì¶”ì¸¡í•˜ì§€ ë§ê³ , PDFì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”**
3. **í•œ ê¸€ì, í•œ ìˆ«ìë¼ë„ í‹€ë¦¬ë©´ ì•ˆë©ë‹ˆë‹¤**

ë³´ë„ìë£Œ ë‚´ìš©:
{content}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

---
title: "PDF ì œëª©ì„ ì •í™•íˆ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì„¸ìš”"
date: "YYYY-MM-DD"
tags: ["íƒœê·¸1"]
thumbnail_summary: "80ì ì´ë‚´ í•œì¤„ìš”ì•½"
source_url: "{source_url}"
source_pdf: "{pdf_filename}"
---

# ìƒì„¸ ìš”ì•½

## ğŸ“‹ ì£¼ìš” ë‚´ìš©
PDFì˜ ëª¨ë“  ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. íŠ¹íˆ ìˆ«ì, ë‚ ì§œ, ì¥ì†Œ, ì°¸ì„ì ë“±ì„ ì›ë¬¸ê³¼ ì •í™•íˆ ì¼ì¹˜ì‹œí‚¤ì„¸ìš”.

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸
- ì£¼ìš” ëŒ€ìƒ, ì¼ì •, ì¥ì†Œ, ì°¸ì—¬ë°©ë²•, í˜œíƒ ë“±

## ğŸ“ ì„¸ë¶€ë¬¸ì˜
[OCRë¡œ ë³„ë„ ì¶”ì¶œí•œ ì—°ë½ì²˜ê°€ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤]

ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸: {', '.join(AVAILABLE_TAGS)}
ë‚´ìš©ì˜ í•µì‹¬ ëª©ì ì— ê°€ì¥ ì í•©í•œ íƒœê·¸ 1ê°œë§Œ ì„ íƒí•˜ì„¸ìš”.

**íƒœê·¸ ë¶„ë¥˜ ê°€ì´ë“œë¼ì¸:**
â€¢ ì²­ë…„Â·êµìœ¡: ì²­ë…„ í”„ë¡œê·¸ë¨, êµìœ¡ ê³¼ì •, ëŒ€í•™ìƒ í–‰ì‚¬, ì¸ì¬ì–‘ì„±, ê²½ì§„ëŒ€íšŒ, í•´í‚¹ë°©ì–´ëŒ€íšŒ, ì½”ë”©ëŒ€íšŒ, í•™ìƒ ì°¸ì—¬ ëŒ€íšŒ
â€¢ ì¼ìë¦¬Â·ê²½ì œ: ê¸°ì—… ìœ ì¹˜, íˆ¬ì ìœ ì¹˜, ì·¨ì—… ì§€ì›, ê²½ì œ ì •ì±…, ì‚°ì—… ë°œì „
â€¢ ë³µì§€Â·ê±´ê°•: ë³µì§€ ì„œë¹„ìŠ¤, ì˜ë£Œ ì§€ì›, ê±´ê°• ê´€ë¦¬, ëŒë´„ ì„œë¹„ìŠ¤
â€¢ êµí†µÂ·ì£¼ê±°: êµí†µ ì¸í”„ë¼, ì£¼íƒ ì •ì±…, ëŒ€ì¤‘êµí†µ, ë„ë¡œ ê±´ì„¤
â€¢ ë¬¸í™”Â·ê´€ê´‘: ì¶•ì œ, ê³µì—°, ì „ì‹œ, ê´€ê´‘ ì§„í¥, ë¬¸í™” í–‰ì‚¬
â€¢ ì•ˆì „Â·í™˜ê²½: ì¬ë‚œ ëŒ€ì‘, í™”ì¬ ì•ˆì „, í™˜ê²½ ë³´í˜¸, ë°©ì—­, í•˜ìˆ˜ì²˜ë¦¬, ìˆ˜ì§ˆ ê´€ë¦¬
â€¢ í–‰ì •Â·ì†Œì‹: í–‰ì • ì„œë¹„ìŠ¤, ì‹œë¯¼ ì°¸ì—¬, ì •ì±… ë°œí‘œ, ì‹œì¥ ì—…ë¬´, íšŒì˜, ë¯¼ì› ì²˜ë¦¬, ëŒ€ì™¸ í˜‘ë ¥, í•´ì™¸ êµë¥˜, êµ­ì œ í–‰ì‚¬
"""
            
            logger.info("ğŸ¤– GPT ìš”ì•½ ìƒì„± ì¤‘...")
            
            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "system", 
                        "content": """ë¶€ì‚°ì‹œì²­ ë³´ë„ìë£Œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ğŸ¯ í•µì‹¬ ë¯¸ì…˜: ì •í™•í•˜ê³  ìƒì„¸í•œ ìš”ì•½ ìƒì„±

ğŸ“‹ í•„ìˆ˜ ì—­ëŸ‰:
- PDF ë‚´ìš© ì™„ë²½ ì´í•´
- ì •í™•í•œ ì •ë³´ ì¶”ì¶œ (ìˆ«ì, ë‚ ì§œ, ê³ ìœ ëª…ì‚¬)
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìš”ì•½
- ì ì ˆí•œ íƒœê·¸ ë¶„ë¥˜

âš ï¸ ì ˆëŒ€ ì›ì¹™:
- í˜„ì¬ PDFì—ì„œë§Œ ì •ë³´ ì¶”ì¶œ (ì´ì „ ê¸°ì–µ ì‚¬ìš© ê¸ˆì§€)
- ì¶”ì¸¡ ê¸ˆì§€, ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©
- í•œ ê¸€ì, í•œ ìˆ«ìë„ í‹€ë¦¬ë©´ ì•ˆë¨

ì •í™•ì„±ì´ ìƒëª…ì…ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ì‘ì—…í•˜ì„¸ìš”."""
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            summary_text = response.choices[0].message.content.strip()
            if not summary_text:
                return None
            
            # frontmatter íŒŒì‹±
            metadata = self._parse_frontmatter(summary_text)
            if not metadata:
                return None
            
            # GPT íƒœê·¸ ê²€ì¦
            gpt_tags = metadata.get('tags', [])
            validated_tags = self._validate_gpt_tags(gpt_tags, content)
            metadata['tags'] = validated_tags
            
            # ì•ˆì „í•œ source_url ì„¤ì •
            if not metadata.get('source_url') or metadata.get('source_url') == "ì›ë¬¸_URL_ì—¬ê¸°_ì…ë ¥":
                metadata['source_url'] = source_url
                summary_text = summary_text.replace("ì›ë¬¸_URL_ì—¬ê¸°_ì…ë ¥", source_url)
            
            # ğŸ”§ source_pdf í•„ë“œ í™•ì¸ ë° ì„¤ì •
            if not metadata.get('source_pdf'):
                metadata['source_pdf'] = pdf_filename
            
            # ë§ˆí¬ë‹¤ìš´ ì·¨ì†Œì„  ë¬¸ë²• ì •ì œ
            summary_text = self._fix_markdown_strikethrough(summary_text)
            
            logger.info(f"âœ… GPT ìš”ì•½ ìƒì„± ì™„ë£Œ (íƒœê·¸: {validated_tags}, PDF: {pdf_filename})")
            return {
                'metadata': metadata,
                'content': summary_text
            }
                
        except Exception as e:
            logger.error(f"âŒ GPT ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _validate_gpt_tags(self, gpt_tags: List[str], content: str) -> List[str]:
        """GPT íƒœê·¸ ê²€ì¦ (GPT ìš°ì„ , ìµœì†Œí•œì˜ ë³´ì •ë§Œ)"""
        try:
            # GPTê°€ ì„ íƒí•œ íƒœê·¸ê°€ ìœ íš¨í•œ íƒœê·¸ ëª©ë¡ì— ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            for tag in gpt_tags:
                if tag in AVAILABLE_TAGS:
                    logger.info(f"âœ… GPT íƒœê·¸ ê²€ì¦ í†µê³¼: {tag}")
                    return [tag]
            
            # GPTê°€ ìœ íš¨í•˜ì§€ ì•Šì€ íƒœê·¸ë¥¼ ì„ íƒí–ˆì„ ë•Œë§Œ ìµœì†Œí•œì˜ í‚¤ì›Œë“œ ë³´ì •
            logger.warning(f"âš ï¸ GPT íƒœê·¸ ë¬´íš¨: {gpt_tags}, í‚¤ì›Œë“œ ë³´ì • ì ìš©")
            
            text_lower = content.lower()
            
            # 8ê°œ íƒœê·¸ì— ë§ì¶˜ í‚¤ì›Œë“œ ë§¤ì¹­
            if any(keyword in text_lower for keyword in ["ì²­ë…„", "ëŒ€í•™ìƒ", "í•™ìƒ", "êµìœ¡", "í•´í‚¹", "ê²½ì§„ëŒ€íšŒ", "ì¸ì¬ì–‘ì„±", "ì½”ë”©", "í•´í‚¹ë°©ì–´", "ëŒ€íšŒ"]):
                return ["ì²­ë…„Â·êµìœ¡"]
            elif any(keyword in text_lower for keyword in ["íˆ¬ì", "ê¸°ì—…", "ì¼ìë¦¬", "ê²½ì œ", "ì‚°ì—…"]):
                return ["ì¼ìë¦¬Â·ê²½ì œ"]
            elif any(keyword in text_lower for keyword in ["ë³µì§€", "ê±´ê°•", "ì˜ë£Œ", "ëŒë´„"]):
                return ["ë³µì§€Â·ê±´ê°•"]
            elif any(keyword in text_lower for keyword in ["êµí†µ", "ì£¼ê±°", "ì£¼íƒ", "ë²„ìŠ¤", "ì§€í•˜ì² "]):
                return ["êµí†µÂ·ì£¼ê±°"]
            elif any(keyword in text_lower for keyword in ["ë¬¸í™”", "ì¶•ì œ", "ê³µì—°", "ì „ì‹œ", "ê´€ê´‘", "ì—¬ê°€"]):
                return ["ë¬¸í™”Â·ê´€ê´‘"]
            elif any(keyword in text_lower for keyword in ["ì•ˆì „", "í™”ì¬", "í™˜ê²½", "ì¬ë‚œ", "í•˜ìˆ˜", "ìˆ˜ì§ˆ"]):
                return ["ì•ˆì „Â·í™˜ê²½"]
            else:
                return ["í–‰ì •Â·ì†Œì‹"]  # ê¸°ë³¸ê°’
            
        except Exception as e:
            logger.error(f"âŒ íƒœê·¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return ["í–‰ì •Â·ì†Œì‹"]
    
    def _fix_markdown_strikethrough(self, text: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ ì·¨ì†Œì„  ë¬¸ë²• ì •ì œ"""
        try:
            # íŒ¨í„´ 1: ìˆ«ìì¼~~ìˆ«ìì¼ â†’ ìˆ«ìì¼-ìˆ«ìì¼
            text = re.sub(r'(\d+ì¼)~~(\d+ì¼)', r'\1-\2', text)
            
            # íŒ¨í„´ 2: ìˆ«ìì›” ìˆ«ìì¼~~ìˆ«ìì¼ â†’ ìˆ«ìì›” ìˆ«ìì¼-ìˆ«ìì¼
            text = re.sub(r'(\d+ì›”\s*\d+ì¼)~~(\d+ì¼)', r'\1-\2', text)
            
            # íŒ¨í„´ 3: ë…„.ì›”.ì¼~~ë…„.ì›”.ì¼ â†’ ë…„.ì›”.ì¼-ë…„.ì›”.ì¼
            text = re.sub(r'(\d+\.\d+\.\d+)~~(\d+\.\d+\.\d+)', r'\1-\2', text)
            
            # íŒ¨í„´ 4: ì‹œê°„~~ì‹œê°„ â†’ ì‹œê°„-ì‹œê°„
            text = re.sub(r'(\d+:\d+)~~(\d+:\d+)', r'\1-\2', text)
            
            # íŒ¨í„´ 5: ì¼ë°˜ì ì¸ ë²”ìœ„ í‘œê¸° A~~B â†’ A-B
            text = re.sub(r'([ê°€-í£\d\s]+)~~([ê°€-í£\d\s]+)', r'\1-\2', text)
            
            return text
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆí¬ë‹¤ìš´ ì·¨ì†Œì„  ë¬¸ë²• ì •ì œ ì‹¤íŒ¨: {e}")
            return text
    
    def _parse_frontmatter(self, content: str) -> Optional[Dict]:
        """ğŸ”§ frontmatter íŒŒì‹± (source_pdf í•„ë“œ ì¶”ê°€)"""
        try:
            if not content.startswith('---'):
                return None
            
            end_idx = content.find('---', 3)
            if end_idx == -1:
                return None
            
            frontmatter_text = content[3:end_idx].strip()
            metadata = {}
            
            for line in frontmatter_text.split('\n'):
                line = line.strip()
                if not line or ':' not in line:
                    continue
                
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip().strip('"\'')
                
                if key == 'tags':
                    if value.startswith('[') and value.endswith(']'):
                        tag_content = value[1:-1].strip()
                        if tag_content:
                            tags = [tag.strip().strip('"\'') for tag in tag_content.split(',') if tag.strip()]
                            metadata[key] = tags if tags else ["í–‰ì •Â·ì†Œì‹"]
                        else:
                            metadata[key] = ["í–‰ì •Â·ì†Œì‹"]
                    else:
                        metadata[key] = [value] if value else ["í–‰ì •Â·ì†Œì‹"]
                else:
                    metadata[key] = value
            
            # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’
            if 'title' not in metadata:
                metadata['title'] = "ë¶€ì‚°ì‹œ ë³´ë„ìë£Œ"
            if 'date' not in metadata:
                metadata['date'] = datetime.now().strftime("%Y-%m-%d")
            if 'tags' not in metadata:
                metadata['tags'] = ["í–‰ì •Â·ì†Œì‹"]
            if 'thumbnail_summary' not in metadata:
                metadata['thumbnail_summary'] = "ë¶€ì‚°ì‹œ ë³´ë„ìë£Œì…ë‹ˆë‹¤."
            if 'source_pdf' not in metadata:
                metadata['source_pdf'] = ""
            
            return metadata
            
        except Exception as e:
            logger.error(f"âŒ frontmatter íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    def create_filename_from_metadata(self, metadata: Dict) -> str:
        """ë©”íƒ€ë°ì´í„°ë¡œë¶€í„° íŒŒì¼ëª… ìƒì„±"""
        try:
            title = metadata.get('title', 'ë³´ë„ìë£Œ')
            date = metadata.get('date', datetime.now().strftime("%Y-%m-%d"))
            tags = metadata.get('tags', ['í–‰ì •Â·ì†Œì‹'])
            
            clean_date = date.replace('-', '')
            main_tag = tags[0] if tags else 'í–‰ì •Â·ì†Œì‹'
            clean_title = self._clean_title_for_filename(title)
            
            filename = f"{clean_date}_{main_tag}_{clean_title}.md"
            
            if len(filename) > 100:
                clean_title = clean_title[:50]
                filename = f"{clean_date}_{main_tag}_{clean_title}.md"
            
            return filename
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            return f"{timestamp}_ë³´ë„ìë£Œ.md"
    
    def _clean_title_for_filename(self, title: str) -> str:
        """íŒŒì¼ëª…ìš© ì œëª© ì •ë¦¬"""
        try:
            clean_title = re.sub(r'[<>:"/\\|?*\[\]{}]', '', title)
            clean_title = re.sub(r'\s+', '_', clean_title.strip())
            clean_title = re.sub(r'_+', '_', clean_title)
            
            # ì¡°ì‚¬ ì œê±° ë° ë‹¨ì–´ ì œí•œ
            particles = ['ì˜', 'ì„', 'ë¥¼', 'ì—', 'ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì´', 'ê°€', 'ëŠ”', 'ë„']
            words = [w for w in clean_title.split('_') if w and w not in particles and len(w) > 1]
            
            if len(words) > 4:
                words = words[:4]
            
            clean_title = '_'.join(words)
            if len(clean_title) > 30:
                clean_title = clean_title[:30]
            
            return clean_title.strip('_') if clean_title else "ë³´ë„ìë£Œ"
            
        except Exception as e:
            return "ë³´ë„ìë£Œ"
    
    def save_markdown(self, summary_data: Dict, filename: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥"""
        try:
            filepath = Path(self.output_dir) / filename
            
            # íŒŒì¼ ì¡´ì¬ ì²´í¬
            if filepath.exists():
                logger.info(f"â­ï¸ íŒŒì¼ ì´ë¯¸ ì¡´ì¬, ìŠ¤í‚µ: {filename}")
                return str(filepath)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(summary_data['content'])
            
            logger.info(f"âœ… ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥: {filename}")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def process_pdf_file(self, pdf_path: str, source_url: str = "") -> Optional[str]:
        """ğŸ”§ PDF íŒŒì¼ ì²˜ë¦¬ (ì¤‘ë³µ ì²´í¬ ë¡œì§ ì¶”ê°€)"""
        try:
            pdf_filename = Path(pdf_path).name
            logger.info(f"ğŸš€ PDF ì²˜ë¦¬: {pdf_filename}")
            
            # ğŸ”§ 1ë‹¨ê³„: ì¤‘ë³µ ì²´í¬ - ê°™ì€ PDFì—ì„œ ìƒì„±ëœ MD íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            existing_md = self.check_existing_md_for_pdf(pdf_filename)
            if existing_md:
                logger.info(f"â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ PDF: {pdf_filename} â†’ {Path(existing_md).name}")
                return existing_md
            
            # ê¸°ë³¸ URL ì„¤ì •
            if not source_url:
                source_url = "https://www.busan.go.kr/nbtnewsBU"
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            content = self.extract_text_from_pdf(pdf_path)
            if not content:
                return None
            
            # GPT ìš”ì•½ (íƒœê·¸ ë¶„ë¥˜ í¬í•¨, PDF íŒŒì¼ëª… ì „ë‹¬)
            summary_data = self.generate_summary_with_gpt(content, source_url, pdf_filename)
            if not summary_data:
                return None
            
            # ğŸ”§ ê°œì„ ëœ OCRë¡œ ì—°ë½ì²˜ ì¶”ì¶œ ë° êµì²´
            ocr_contact = self.extract_contact_with_ocr(pdf_path)
            
            # ìš”ì•½ ë‚´ìš©ì—ì„œ "## ğŸ“ ì„¸ë¶€ë¬¸ì˜" ì„¹ì…˜ êµì²´
            summary_content = summary_data['content']
            contact_pattern = r'## ğŸ“ ì„¸ë¶€ë¬¸ì˜.*?(?=\n##|\Z)'
            new_contact_section = f"## ğŸ“ ì„¸ë¶€ë¬¸ì˜\n{ocr_contact}"
            
            summary_content = re.sub(contact_pattern, new_contact_section, summary_content, flags=re.DOTALL)
            summary_data['content'] = summary_content
            
            # íŒŒì¼ëª… ìƒì„± ë° ì €ì¥
            metadata = summary_data['metadata']
            filename = self.create_filename_from_metadata(metadata)
            
            # íŒŒì¼ ì¡´ì¬ ì²´í¬ ë° ì¤‘ë³µ ë°©ì§€
            md_path = self.save_markdown(summary_data, filename)
            
            if md_path:
                tag = metadata.get('tags', ['ë¯¸ë¶„ë¥˜'])[0]
                logger.info(f"ğŸ‰ ì™„ë£Œ: {pdf_filename} â†’ {filename} (íƒœê·¸: {tag}, ì—°ë½ì²˜: {ocr_contact})")
                return md_path
            
            return None
                
        except Exception as e:
            logger.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨ {Path(pdf_path).name}: {e}")
            return None
    
    def process_all_pdfs(self, source_urls: Dict[str, str] = None) -> List[str]:
        """ëª¨ë“  PDF íŒŒì¼ ì²˜ë¦¬"""
        try:
            pdf_files = list(Path(PDF_DIR).glob("*.pdf"))
            if not pdf_files:
                logger.warning("âš ï¸ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            logger.info(f"ğŸ“‹ ì²˜ë¦¬í•  PDF: {len(pdf_files)}ê°œ")
            
            generated_files = []
            for idx, pdf_path in enumerate(pdf_files, 1):
                logger.info(f"ğŸ“„ [{idx}/{len(pdf_files)}] {pdf_path.name}")
                
                source_url = ""
                if source_urls and pdf_path.name in source_urls:
                    source_url = source_urls[pdf_path.name]
                
                md_file = self.process_pdf_file(str(pdf_path), source_url)
                if md_file:
                    generated_files.append(md_file)
                
                if idx < len(pdf_files):
                    time.sleep(2)  # API ì œí•œ
            
            logger.info(f"ğŸ‰ ì²˜ë¦¬ ì™„ë£Œ: {len(generated_files)}ê°œ ìƒì„±")
            return generated_files
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []


# ğŸ§ª í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_ocr_extraction():
    """OCR ì—°ë½ì²˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    summarizer = BusanNewsSummarizer()
    
    # í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ ê²½ë¡œ
    test_pdf_path = "./data/pdfs/test_document.pdf"
    
    if os.path.exists(test_pdf_path):
        print("ğŸ§ª OCR ì—°ë½ì²˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        contact = summarizer.extract_contact_with_ocr(test_pdf_path)
        print(f"ğŸ“ ì¶”ì¶œëœ ì—°ë½ì²˜: {contact}")
    else:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


def test_duplicate_check():
    """ğŸ§ª ì¤‘ë³µ ì²´í¬ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    summarizer = BusanNewsSummarizer()
    
    # ê¸°ì¡´ MD íŒŒì¼ë“¤ ì²´í¬
    test_filename = "test_document.pdf"
    existing_md = summarizer.check_existing_md_for_pdf(test_filename)
    
    if existing_md:
        print(f"âœ… ì¤‘ë³µ ì²´í¬ ì„±ê³µ: {test_filename} â†’ {existing_md}")
    else:
        print(f"âš ï¸ ê¸°ì¡´ MD íŒŒì¼ ì—†ìŒ: {test_filename}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_ocr_extraction()
    test_duplicate_check()